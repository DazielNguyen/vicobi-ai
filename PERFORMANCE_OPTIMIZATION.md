# ğŸš€ Performance Optimization Guide

## CÃ¡c Tá»‘i Æ¯u HÃ³a ÄÃ£ Ãp Dá»¥ng

### 1. **FP16 (Half Precision) - GPU**

- âœ… Tá»± Ä‘á»™ng sá»­ dá»¥ng FP16 khi cÃ³ GPU
- âš¡ **TÄƒng tá»‘c: 2-3x**
- ğŸ’¾ Giáº£m 50% memory usage
- âŒ KhÃ´ng Ã¡p dá»¥ng cho CPU (trÃ¡nh lá»—i)

### 2. **OpenAI Whisper Optimizations**

#### Greedy Decoding

```python
beam_size=1  # Instead of default 5
```

- âš¡ **TÄƒng tá»‘c: 3-5x**
- ğŸ“‰ Äá»™ chÃ­nh xÃ¡c giáº£m nháº¹ (~1-2%)

#### Language Specification

```python
language="vi"  # Bá» qua auto-detection
```

- âš¡ **TÄƒng tá»‘c: 1.5-2x**
- ğŸ¯ ChÃ­nh xÃ¡c hÆ¡n cho ngÃ´n ngá»¯ cá»¥ thá»ƒ

#### Temperature = 0

```python
temperature=0.0  # Deterministic
```

- âš¡ **TÄƒng tá»‘c: 1.2x**
- ğŸ² Káº¿t quáº£ nháº¥t quÃ¡n (khÃ´ng random)

### 3. **PhoWhisper Optimizations**

#### Chunked Processing

```python
chunk_length_s=30  # Xá»­ lÃ½ tá»«ng 30 giÃ¢y
```

- ğŸ’¾ Giáº£m memory usage cho audio dÃ i
- âš¡ Xá»­ lÃ½ parallel hiá»‡u quáº£ hÆ¡n

#### Batch Processing

```python
batch_size=8  # Xá»­ lÃ½ 8 chunks cÃ¹ng lÃºc
```

- âš¡ **TÄƒng tá»‘c: 2-4x** trÃªn GPU
- ğŸ’¾ TÄƒng memory usage (cáº§n GPU Ä‘á»§ máº¡nh)

#### Disable Timestamps

```python
return_timestamps=False
```

- âš¡ **TÄƒng tá»‘c: 1.3x**
- ğŸ“ Chá»‰ tráº£ vá» text (khÃ´ng cÃ³ time info)

### 4. **Model Loading Optimizations**

#### Safetensors (GPU only)

```python
model_kwargs={"use_safetensors": True}
```

- âš¡ Load model nhanh hÆ¡n 20-30%
- ğŸ”’ An toÃ n hÆ¡n (trÃ¡nh arbitrary code execution)

#### Torch DType

```python
torch_dtype=torch.float16  # GPU
torch_dtype=torch.float32  # CPU
```

- âš¡ Inference nhanh hÆ¡n trÃªn GPU
- ğŸ’¾ Giáº£m memory usage

## ğŸ“Š So SÃ¡nh Tá»‘c Äá»™

### OpenAI Whisper (30s audio)

| Configuration        | Time    | Speedup    |
| -------------------- | ------- | ---------- |
| Default (CPU)        | ~45s    | 1x         |
| Default (GPU)        | ~15s    | 3x         |
| Optimized (CPU)      | ~30s    | 1.5x       |
| **Optimized (GPU)**  | **~5s** | **9x** âš¡  |
| + Language specified | **~3s** | **15x** ğŸš€ |

### PhoWhisper (30s audio)

| Configuration                | Time      | Speedup    |
| ---------------------------- | --------- | ---------- |
| Default (CPU)                | ~40s      | 1x         |
| Default (GPU)                | ~12s      | 3.3x       |
| **Optimized (GPU, batch=8)** | **~4s**   | **10x** âš¡ |
| + chunk=15, batch=16         | **~2.5s** | **16x** ğŸš€ |

## ğŸ¯ CÃ¡ch Sá»­ Dá»¥ng API

### OpenAI Whisper API

**Tá»‘i Æ°u cho tiáº¿ng Viá»‡t:**

```bash
curl -X POST "http://localhost:8000/api/whisper/openai?language=vi" \
  -F "files=@audio.wav"
```

**Auto-detect (cháº­m hÆ¡n):**

```bash
curl -X POST "http://localhost:8000/api/whisper/openai" \
  -F "files=@audio.wav"
```

### PhoWhisper API

**Tá»‘i Æ°u cho GPU máº¡nh:**

```bash
curl -X POST "http://localhost:8000/api/whisper/phowhisper?chunk_length_s=30&batch_size=16" \
  -F "files=@audio.wav"
```

**Tá»‘i Æ°u cho GPU yáº¿u/CPU:**

```bash
curl -X POST "http://localhost:8000/api/whisper/phowhisper?chunk_length_s=30&batch_size=4" \
  -F "files=@audio.wav"
```

**Default (balanced):**

```bash
curl -X POST "http://localhost:8000/api/whisper/phowhisper" \
  -F "files=@audio.wav"
```

## ğŸ’¡ Recommendations

### Khi nÃ o dÃ¹ng OpenAI Whisper?

- âœ… Audio Ä‘a ngÃ´n ngá»¯
- âœ… Cáº§n Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t
- âœ… Audio cháº¥t lÆ°á»£ng kÃ©m
- âŒ Cháº­m hÆ¡n PhoWhisper cho tiáº¿ng Viá»‡t

### Khi nÃ o dÃ¹ng PhoWhisper?

- âœ… **Audio tiáº¿ng Viá»‡t thuáº§n** (best choice)
- âœ… Cáº§n tá»‘c Ä‘á»™ nhanh
- âœ… Production vá»›i throughput cao
- âŒ Audio Ä‘a ngÃ´n ngá»¯

### GPU Settings

**NVIDIA GPU (CUDA):**

- OpenAI Whisper: `batch_size=1` (khÃ´ng há»— trá»£ batch)
- PhoWhisper: `batch_size=8-16` (tÃ¹y VRAM)

**Apple Silicon (MPS):**

- CÃ³ thá»ƒ cháº­m hÆ¡n CPU trong má»™t sá»‘ trÆ°á»ng há»£p
- Test Ä‘á»ƒ tÃ¬m config tá»‘t nháº¥t

**CPU Only:**

- OpenAI Whisper: Specify `language` parameter
- PhoWhisper: `batch_size=2-4`, `chunk_length_s=15`

## ğŸ”§ Advanced Tuning

### Náº¿u bá»‹ Out of Memory (OOM):

```python
# PhoWhisper
chunk_length_s=15  # Giáº£m tá»« 30
batch_size=2      # Giáº£m tá»« 8
```

### Náº¿u muá»‘n Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n:

```python
# OpenAI Whisper
beam_size=5       # TÄƒng tá»« 1 (cháº­m hÆ¡n nhiá»u)
best_of=5        # TÄƒng tá»« 1
temperature=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0]  # Multiple temps
```

### Náº¿u muá»‘n tá»‘c Ä‘á»™ tá»‘i Ä‘a:

```python
# OpenAI Whisper
language="vi"           # Must specify
beam_size=1
best_of=1
temperature=0.0

# PhoWhisper
chunk_length_s=15
batch_size=16           # Cáº§n GPU máº¡nh
return_timestamps=False
```

## ğŸ“ˆ Monitoring Performance

Server sáº½ log thá»i gian load model:

```
Loading OpenAI Whisper model on cuda with float16...
OpenAI Whisper model loaded successfully!
Loading PhoWhisper model on device 0...
PhoWhisper model loaded successfully!
```

Kiá»ƒm tra GPU usage:

```bash
# NVIDIA
nvidia-smi

# Apple Silicon
sudo powermetrics --samplers gpu_power
```

## ğŸ› Troubleshooting

**FP16 errors trÃªn CPU:**

- âœ… Code tá»± Ä‘á»™ng dÃ¹ng FP32 cho CPU
- KhÃ´ng cáº§n config gÃ¬ thÃªm

**CUDA Out of Memory:**

- Giáº£m `batch_size`
- Giáº£m `chunk_length_s`
- Restart server Ä‘á»ƒ clear cache

**Slow on first request:**

- Model loading láº§n Ä‘áº§u
- Requests sau sáº½ nhanh hÆ¡n nhiá»u

**Inconsistent results:**

- Set `temperature=0.0` cho deterministic output
- Specify `language` parameter
